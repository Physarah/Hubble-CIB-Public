data_hubble = data.frame(x = training$sun_alt, y = training$background_abmag)
ggplot(aes(x , y), data = data_hubble) +
geom_point(cex = 2, pch = 20) +
geom_smooth()+
ylab("background") +
xlab("sunangle") +
ggtitle("background as a function of sunangle")
df1_train <-data.frame(x = training$sun_alt , y = training$background_abmag)
df2_test <-data.frame(x = testing$sun_alt , y = testing$background_abmag)
ggplot(df1_train, aes(x,y))+ geom_point(aes(color="Training Data"), pch = 20)+
geom_point(data=df2_test, aes(color="Testing Data"), pch = 18)+
labs(color="Split Dataset")+
ylab("Background")+
xlab("Sunangle")+
ggtitle("background as a function of sunangle with training and test data")
# Find best polynomial fit
mse_calc<- function(sm)
mean(sm$residuals^2)
order <- 1:10
mse_test <- c()
mse_train <- c()
for(n in order){
fit <- lm(background_abmag ~ poly(sun_alt, n, raw=TRUE), data = training)
mse_train[n] <- mse_calc(summary(fit))
prediciton_test <- predict(fit, newdata = testing)
mse_test[n] <- mean((testing$background_abmag - prediciton_test)^2)
}
mse_data <- data.frame(x = order, y = mse_train)
mse2_data <- data.frame(x = order, y = mse_test)
ggplot(aes(x , y), data = mse_data) +
geom_line(aes(color="Training Data"), pch = 20, lty = 5)+
geom_line(data=mse2_data, aes(color="Training + Testing Data"), pch = 18, lty = 5)+
labs(color="Model")+
ylab("Mean Standard Error") +
xlab("Polynomial Order") +
ggtitle("MSE as a function of polynomial order")
hubble_test_cleaned2 <- subset(hubble_test2, hubble_test2$background_abmag > 75)
hubble_test <- data.frame(F606W)
hubble_test2 <- data.frame(good_data)
pairs(hubble_test, pch = 1, cex = 0.3, diag.panel=panel.hist)
cor(hubble_test)
pairs(hubble_test_cleaned2, pch = 1, cex = 0.3, diag.panel=panel.hist)
cor(hubble_test_cleaned2)
hubble_test_cleaned2 <- subset(hubble_test2, hubble_test2$background_abmag > 75 & hubble_test2$background_abmag != "Inf")
hubble_test_cleaned2 <- subset(hubble_test2, hubble_test2$background_abmag > 75 & hubble_test2$background_abmag != "Inf")
hubble_test <- data.frame(F606W)
hubble_test2 <- data.frame(good_data)
pairs(hubble_test, pch = 1, cex = 0.3, diag.panel=panel.hist)
cor(hubble_test)
pairs(hubble_test_cleaned2, pch = 1, cex = 0.3, diag.panel=panel.hist)
cor(hubble_test_cleaned2)
# Training and test data sets (not brilliant with this data set due to doubles, small size)
shuffled = sample(nrow(hubble_test_cleaned2))
training = hubble_test_cleaned2[shuffled[1:(length(shuffled)*0.8)],]
testing = hubble_test_cleaned2[shuffled[(length(shuffled)*0.8+1):length(shuffled)],]
data_hubble = data.frame(x = training$sun_alt, y = training$background_abmag)
ggplot(aes(x , y), data = data_hubble) +
geom_point(cex = 2, pch = 20) +
geom_smooth()+
ylab("background") +
xlab("sunangle") +
ggtitle("background as a function of sunangle")
df1_train <-data.frame(x = training$sun_alt , y = training$background_abmag)
df2_test <-data.frame(x = testing$sun_alt , y = testing$background_abmag)
ggplot(df1_train, aes(x,y))+ geom_point(aes(color="Training Data"), pch = 20)+
geom_point(data=df2_test, aes(color="Testing Data"), pch = 18)+
labs(color="Split Dataset")+
ylab("Background")+
xlab("Sunangle")+
ggtitle("background as a function of sunangle with training and test data")
# Find best polynomial fit
mse_calc<- function(sm)
mean(sm$residuals^2)
order <- 1:10
mse_test <- c()
mse_train <- c()
for(n in order){
fit <- lm(background_abmag ~ poly(sun_alt, n, raw=TRUE), data = training)
mse_train[n] <- mse_calc(summary(fit))
prediciton_test <- predict(fit, newdata = testing)
mse_test[n] <- mean((testing$background_abmag - prediciton_test)^2)
}
mse_data <- data.frame(x = order, y = mse_train)
mse2_data <- data.frame(x = order, y = mse_test)
ggplot(aes(x , y), data = mse_data) +
geom_line(aes(color="Training Data"), pch = 20, lty = 5)+
geom_line(data=mse2_data, aes(color="Training + Testing Data"), pch = 18, lty = 5)+
labs(color="Model")+
ylab("Mean Standard Error") +
xlab("Polynomial Order") +
ggtitle("MSE as a function of polynomial order")
ggplot(data_hubble, aes(x , y)) +
geom_point(pch = 20, cex = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x,1), alpha = 0.001, colour="blue", cex = 0.5)+
stat_smooth(method = "lm", formula = y ~ poly(x,2), alpha = 0.001, colour="green", cex = 0.5)+
stat_smooth(method = "lm", formula = y ~ poly(x,3), alpha = 0.001, colour="red", cex = 0.5)+
ylab("Background")+
xlab("Sunangle")+
ggtitle("Comparing Polynomials")
# Check it works with different seeds for training and testing data sets
iters <- 1:500
best_order_train <- c()
best_order_test <- c()
for (m in iters){
set.seed(m)
shuffled = sample(nrow(hubble_test))
training = hubble_test[shuffled[1:(length(shuffled)*0.8)],]
testing = hubble_test[shuffled[(length(shuffled)*0.8+1):length(shuffled)],]
order <- 1:10
mse_train2 <- c()
mse_test2 <- c()
for(n in order){
fit <- lm(background ~ poly(sunangle, n, raw=TRUE), data = training)
mse_train2[n] <- mse_calc(summary(fit))
prediciton_test <- predict(fit, newdata = testing)
mse_test2[n] <- mean((testing$background - prediciton_test)^2)
}
index_train <- match(min(mse_train2),mse_train2)
best_order_train[m] <- order[index_train]
index_test <- match(min(mse_test2),mse_test2)
best_order_test[m] <- order[index_test]
}
qplot(best_order_train, geom="histogram", xlab = 'Order', ylab = 'Counts', main = 'Best order using only training data')
qplot(best_order_test, geom="histogram", xlab = 'Order', ylab = 'Counts', main = 'Best order using test and training data', binwidth = 0.5)
# Same thing with 10 fold cross validation
iters2 <- 1:100
best_order_glm <- c()
error <- c()
for (m in iters2){
set.seed(m)
shuffled = sample(nrow(file_used))
training = file_used[shuffled[1:(length(shuffled)*0.8)],]
testing = file_used[shuffled[(length(shuffled)*0.8+1):length(shuffled)],]
for (i in 1:10){
glm.fit=glm(background_abmag ~ poly(sun_alt, i, raw=TRUE), data = training)
error[i]=cv.glm(training,glm.fit,K=5)$delta[1]
}
index_glm <- match(min(error),error)
best_order_glm[m] <- order[index_glm]
}
file_used = hubble_test_cleaned2
# Same thing with 10 fold cross validation
iters2 <- 1:100
best_order_glm <- c()
error <- c()
for (m in iters2){
set.seed(m)
shuffled = sample(nrow(file_used))
training = file_used[shuffled[1:(length(shuffled)*0.8)],]
testing = file_used[shuffled[(length(shuffled)*0.8+1):length(shuffled)],]
for (i in 1:10){
glm.fit=glm(background_abmag ~ poly(sun_alt, i, raw=TRUE), data = training)
error[i]=cv.glm(training,glm.fit,K=5)$delta[1]
}
index_glm <- match(min(error),error)
best_order_glm[m] <- order[index_glm]
}
# Clear over fitting here (poor sample size)
qplot(best_order_glm, geom="histogram", xlab = 'Order', ylab = 'Counts', main = 'Best order using 5 fold Cross Validation', binwidth = 0.5)
mean(F606W$backgroug_abmag)
F606W_cleaned <- subset(F606W, F606W$background_abmag != "Inf")
high_shine <- ifelse(F606W_cleaned$background_abmag > 25, "yes", "no")
mean(F606W_cleaned$backgroug_abmag)
mean(F606W_cleaned$backgroud_abmag)
mean(F606W_cleaned$background_abmag)
high_shine <- ifelse(F606W_cleaned$background_abmag > 79, "yes", "no")
print(high_shine)
new_hubble <- data.frame(F606W_cleaned, high_shine)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:6]
F606W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F606W-2018-10-19.csv")
F606W_cleaned <- subset(F606W, F606W$background_abmag != "Inf")
high_shine <- ifelse(F606W_cleaned$background_abmag > 79, "yes", "no")
new_hubble <- data.frame(F606W_cleaned, high_shine)
set.seed(333)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 6]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:6]
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 2]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:6]
length(new_hubble_test)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:6]
length(new_hubble_test)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
boston_trainLabels <- predictor_high_medv[samples == 1, 14]
hubble_trainLabels <- predictor_high_background[samples == 1, 3]
hubble_testLabels <- predictor_high_background[samples == 2, 3]
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
hubble_trainLabels <- predictor_high_background[samples == 1, 3]
hubble_testLabels <- predictor_high_background[samples == 2, 3]
k_values <- 1:50
acc <- c()
for(n in k_values){
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
acc[n] <- mean(hubble_prediction==hubble_testLabels)
}
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
hubble_trainLabels <- predictor_high_background[samples == 1, 3]
hubble_testLabels <- predictor_high_background[samples == 2, 3]
k_values <- 1:50
acc <- c()
for(n in k_values){
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
acc[n] <- mean(hubble_prediction==hubble_testLabels)
}
setwd("~/Desktop/Hubble-CIB")
F606W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F606W-2018-10-19.csv")
pairs(F606W)
pairs(F606W, pch = 20)
cor (F606W)
F814W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F814W-2018-10-19.csv")
F814W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F8145-2018-10-19.csv")
F814W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F435W-2018-10-19.csv")
pairs(F814W, pch = 20)
cor (F814W)
F435W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F435W-2018-10-19.csv")
pairs(F435W, pch = 20)
cor (F435W)
F814W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F814W-2018-10-19.csv")
F814W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F815-2018-10-19.csv")
pairs(F814W, pch = 20)
cor (F814W)
library(ggplot2)
F606W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F606W-2018-10-19.csv")
pairs(F606W, pch = 20)
cor (F606W)
F814W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F815-2018-10-19.csv")
pairs(F814W, pch = 20)
cor (F814W)
F435W <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/cosmos_field_F435W-2018-10-19.csv")
pairs(F435W, pch = 20)
cor (F435W)
pairs(deep_sky, pch = 20)
deep_sky <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/deep_sky-2018-10-19.csv")
pairs(deep_sky, pch = 20)
cor (deep_sky)
deep_sky_clean <- subset(deep_sky, deep_sky$background_abmag != NaN)
pairs(deep_sky, pch = 20)
cor (deep_sky)
deep_sky_clean <- subset(deep_sky, deep_sky$background_abmag != is.NaN)
deep_sky_clean <- subset(deep_sky, deep_sky$background_abmag != None)
deep_sky[complete.cases(deep_sky, ]
deep_sky[complete.cases(deep_sky), ]
length(deep_sky)
length(deep_sky$background_abmag)
cleaned <- deep_sky[complete.cases(deep_sky), ]
pairs(cleaned , pch = 20)
pairs(cleaned, pch = 20)
cor (cleaned)
pairs(cleaned, pch = 20, main = "HUDF All Orbits")
pairs(F435W, pch = 20, "COSMOS F435W All Orbits")
pairs(F435W, pch = 20, main = "COSMOS F435W All Orbits")
pairs(F814W, pch = 20, main = "COSMOS F814W All Orbits")
pairs(F606W, pch = 20, main = "COSMOS F606W All Orbits")
cor (F606W)
F606W_orbit1 <- F606W[240:280]
F606W_orbit1 <- F606W[240:280, ]
View(F606W_orbit1)
background_orbit1 <- deep_sky[100:300, ]
F814W_orbit1 <- F814W[23:60, ]
background_orbit1
ggplot(background_orbit1 , aes(x=background_abmag, y=sun_alt )) +
labs(title="The effect of Crime Rate on Housing Price",
x="Crime Rate",
y="Value of Home in Thousands")+
geom_jitter(shape = 3, size = 0.5, width = 0.50)
ggplot(F814W_orbit1 , aes(x=background_abmag, y=sun_alt )) +
labs(title="The effect of Crime Rate on Housing Price",
x="Crime Rate",
y="Value of Home in Thousands")+
geom_jitter(shape = 3, size = 0.5, width = 0.50)
ggplot(F606W_orbit1 , aes(y=background_abmag, x=sun_alt )) +
labs(title="The effect of Crime Rate on Housing Price",
x="Crime Rate",
y="Value of Home in Thousands")+
geom_jitter(shape = 3, size = 0.5, width = 0.50)
ggplot(F606W_orbit1 , aes(y=background_abmag, x=sun_alt )) +
labs(title="The effect of Crime Rate on Housing Price",
x="Sun Altitude (deg)",
y="Background (magAB)")+
geom_jitter(shape = 3, size = 0.5, width = 0.50)
ggplot(F606W_orbit1 , aes(y=background_abmag, x=sun_alt )) +
labs(title="COSMOS F606W 1 Orbits",
x="Sun Altitude (deg)",
y="Background (mag AB)")+
geom_jitter(shape = 3, size = 0.5, width = 0.50)
ggplot(deep_sky , aes(y=background_abmag, x=sun_alt )) +
labs(title="COSMOS F606W 1 Orbits",
x="Sun Altitude (deg)",
y="Background (mag AB)")+
geom_jitter(shape = 3, size = 0.5, width = 0.50)
deep_sky_cleaned <- subset(deep_sky, deep_sky$background_abmag != "Inf")
deep_sky <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/deep_sky-2018-10-19.csv")
deep_sky_cleaned <- subset(deep_sky, deep_sky$background_abmag != "Inf")
high_shine <- ifelse(deep_sky_cleaned$background_abmag > 79, "yes", "no")
new_hubble <- data.frame(deep_sky_cleaned, high_shine)
set.seed(333)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
hubble_trainLabels <- predictor_high_background[samples == 1, 3]
hubble_testLabels <- predictor_high_background[samples == 2, 3]
k_values <- 1:50
acc <- c()
for(n in k_values){
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
acc[n] <- mean(hubble_prediction==hubble_testLabels)
}
library(MASS)
library(class)
library(gmodels)
library(descr)
k_values <- 1:50
acc <- c()
for(n in k_values){
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
acc[n] <- mean(hubble_prediction==hubble_testLabels)
}
deep_sky_cleaned <- na.omit(deep_sky)
high_shine <- ifelse(deep_sky_cleaned$background_abmag > 79, "yes", "no")
new_hubble <- data.frame(deep_sky_cleaned, high_shine)
set.seed(333)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
hubble_trainLabels <- predictor_high_background[samples == 1, 3]
hubble_testLabels <- predictor_high_background[samples == 2, 3]
k_values <- 1:50
acc <- c()
for(n in k_values){
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
acc[n] <- mean(hubble_prediction==hubble_testLabels)
}
high_shine <- ifelse(deep_sky_cleaned$background_abmag > 79, "yes", "no")
new_hubble <- data.frame(deep_sky_cleaned, high_shine)
set.seed(333)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
hubble_trainLabels <- predictor_high_background[samples == 1, 3]
hubble_testLabels <- predictor_high_background[samples == 2, 3]
print(new_hubble_test)
deep_sky <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/deep_sky-2018-10-19.csv")
deep_sky_cleaned <- subset(deep_sky, deep_sky$background_abmag != "Inf")
high_shine <- ifelse(deep_sky_cleaned$background_abmag > 79, "yes", "no")
new_hubble <- data.frame(deep_sky_cleaned, high_shine)
View(new_hubble)
set.seed(333)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
set.seed(333)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 3]
length(new_hubble_test)
hubble_trainLabels <- predictor_high_background[samples == 1, 3]
hubble_testLabels <- predictor_high_background[samples == 2, 3]
k_values <- 1:50
acc <- c()
for(n in k_values){
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
acc[n] <- mean(hubble_prediction==hubble_testLabels)
}
new_hubble_training <- new_hubble[samples == 1, 1:3]
View(new_hubble_test)
new_hubble_training <- new_hubble[samples == 1, 1:3]
View(new_hubble_test)
new_hubble_training <- new_hubble[samples == 1, 3]
View(new_hubble_test)
new_hubble_training <- new_hubble[samples == 1, 1:3]
deep_sky <- read.csv("/Users/Physarah/Desktop/Hubble-CIB/hubble_hunters/data/calibrated_csv/good_data-2018-10-19.csv")
deep_sky_cleaned <- subset(deep_sky, deep_sky$background_abmag != "Inf")
high_shine <- ifelse(deep_sky_cleaned$background_abmag > 79, "yes", "no")
new_hubble <- data.frame(deep_sky_cleaned, high_shine)
set.seed(333)
samples <- sample(2, nrow(new_hubble), replace = TRUE, prob = c(0.67,0.33))
new_hubble_training <- new_hubble[samples == 1, 1:3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 3]
length(new_hubble_test)
View(new_hubble_training
)
new_hubble_training <- new_hubble[samples == 1, 1:3]
length(new_hubble_training)
predictor_high_background <- subset(new_hubble, high_shine == "yes")
new_hubble_test <- predictor_high_background[samples == 2, 1:3]
length(new_hubble_test)
hubble_trainLabels <- predictor_high_background[samples == 1, 1:3]
hubble_testLabels <- predictor_high_background[samples == 2, 1:3]
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
k_values <- 1:50
acc <- c()
for(n in k_values){
hubble_prediction <- knn(train = new_hubble_training, test = new_hubble_test,
cl = hubble_trainLabels, k = n)
acc[n] <- mean(hubble_prediction==hubble_testLabels)
}
high_medv <- ifelse(Boston$medv > 25, "yes", "no")
new_boston <- data.frame(Boston, high_medv)
View(new_boston)
predictor_high_medv <- subset(Boston, high_medv == "yes") #change to rm
# We plot this quickly again just to check
plot(predictor_high_medv$rm,
predictor_high_medv$medv,
xlab = "No. of Rooms in the House",
ylab = "Value of Home in Thousands",
main = "Predictor vs Responce",
pch = 20)
set.seed(333)
samples <- sample(2, nrow(new_boston), replace = TRUE, prob = c(0.67,0.33))
boston_training <- new_boston[samples == 1, 6]
length(boston_training)
boston_test <- predictor_high_medv[samples == 2, 1:6]
length(boston_test)
boston_trainLabels <- predictor_high_medv[samples == 1, 14]
boston_testLabels <- predictor_high_medv[samples == 2, 14]
k_values <- 1:50
acc <- c()
for(n in k_values){
boston_prediction <- knn(train = boston_training, test = boston_test,
cl = boston_trainLabels, k = n)
acc[n] <- mean(boston_prediction==boston_testLabels)
#cm = as.matrix(table(Actual = boston_testLabels, Predicted = boston_prediction))
#acc = sum(diag(cm))/length(boston_trainLabels)
}
set.seed(333)
samples <- sample(2, nrow(new_boston), replace = TRUE, prob = c(0.67,0.33))
boston_training <- new_boston[samples == 1, 6]
length(boston_training)
boston_test <- predictor_high_medv[samples == 2, 1:6]
length(boston_test)
boston_trainLabels <- predictor_high_medv[samples == 1, 14]
boston_testLabels <- predictor_high_medv[samples == 2, 14]
k_values <- 1:50
acc <- c()
for(n in k_values){
boston_prediction <- knn(train = boston_training, test = boston_test,
cl = boston_trainLabels, k = n)
acc[n] <- mean(boston_prediction==boston_testLabels)
#cm = as.matrix(table(Actual = boston_testLabels, Predicted = boston_prediction))
#acc = sum(diag(cm))/length(boston_trainLabels)
}
length(predictor_high_medv$rm)
plot(predictor_high_medv$rm, boston_prediction)
results <- data.frame(x = k_values, y = acc)
ggplot(aes(x , y), data = results) +
geom_point() +
geom_line() +
xlab("K Value") +
ylab("Accuracy (%)") +
ggtitle("The accuracy of the prediction model as a function of k")
max_accuracy <- max(accuracy)
print(max_accuracy)
max_k_value <- subset(k_values, accuracy == max_accuracy)
print(max_k_value)
k_1_accuracy <- accuracy[1]
print(k_1_accuracy)
accuracy2 <- rep(0, 50)
k_values2 <- 1:50
for(n in k_values2){
boston_prediction <- knn(train = boston_training, test = boston_test,
cl = boston_trainLabels, k = n)
accuracy2[n] <- mean(boston_prediction==boston_testLabels)
}
results <- data.frame(x = k_values, y = accuracy2*100)
ggplot(aes(x , y), data = results) +
geom_point() +
geom_line() +
xlab("K Value") +
ylab("Accuracy (%)") +
ggtitle("The accuracy of the prediction model as a function of k")
